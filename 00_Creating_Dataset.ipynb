{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the dataset: Data augmentation\n",
    "In this notebook, I will try to highlight some techniques that can be used to augment the amount of existing data for deep learning purposes. In most cases, more data can be considered beneficial to model training and generalization, especially when dealing with shallower datasets. \n",
    "\n",
    "Augmenting the existing dataset equates to the artificial expansion of existing data using classic image-transforms, like illumination-changes or 2D rotations, translations, scalings ect. To a human observer, rotating or scaling an image can seem fairly trivial, but to a deep learning model the output is a wholly new, hitherto undiscovered datapoint. The greatest advantage? All these new datapoints are labeled, as they inherit from previously labeled sources. \n",
    "\n",
    "## Defining paths, iterators and directories\n",
    "In the `\\data`-folder, we have an existing dataset consisting of 244 images of mushrooms commonly found in the Norwegian flora. These mushrooms are labelled in `data\\image_labels.csv`, and the labels are further described in `data\\label_description.csv`. Although the author would like to point out the pain-stakingly slow work of manually selecting and labelling all datapoints, they are not currently sufficient to train a well-generalized deep learning model. \n",
    "\n",
    "To augment the dataset, we first find an *absolute path* `BASE_DIR` to the current folder (as this can change depending from OS to OS) and make a list `path_list` of path-objects matching a relative pattern. Here, this pattern is defined to be all images ending with `.jpg` (which encompasses both `.jpg` and `.JPG`): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define a BASE_DIR parameter for accuracy of loading files over multiple systems.\n",
    "BASE_DIR = Path(\"00_Creating_Dataset.ipynb\").parent.resolve()\n",
    "\n",
    "# Define a list of image paths and a path to the labels, using a relative pattern:\n",
    "RAW_LABEL_PATH = Path(f\"{BASE_DIR}/data/raw_mushroom_imgs\").rglob('*.csv')\n",
    "raw_img_paths = Path(f\"{BASE_DIR}/data/raw_mushroom_imgs\").rglob('*.jpg')   # NOTE: Notation diff. due to contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a target folder, where the augmented data will be saved. Here, the folder is cleaned after initialization, so as to limit accumulating data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define a path to the target output directory\n",
    "TARGET_DIR = Path(f\"{BASE_DIR}/data/mushroom_imgs\")\n",
    "# Make a directory if there is no directory\n",
    "TARGET_DIR.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "# Empty the directory using another relative pattern\n",
    "target_paths = Path(f\"{TARGET_DIR}\").rglob('*.jpg')\n",
    "for path in target_paths:\n",
    "    os.remove(path)\n",
    "\n",
    "# Define a path for the output csv-file containing the labels of the augmented data\n",
    "TARGET_LABEL_PATH = Path(f\"{BASE_DIR}/data/mushroom_imgs/img_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting the data\n",
    "\n",
    "### Defining the data augmentation pipeline\n",
    "The data augmentation is done through the `torchvision.transforms` library, of which the `Compose` class allows us to define a pipeline of transforms to apply to the image. These can alter the spectral or spatial components of an image, and can be tuned as to give a set of random responses. Naturally, the more randomized transforms one stack atop one another, the less likely it is for any two images to turn out the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define the composite transformation making up our pipeline\n",
    "augmentation_pipeline = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # converts to pillow-image\n",
    "    transforms.Resize((360, 360)),  # resizes the image to (256, 256)\n",
    "    transforms.RandomCrop((224, 224)),  # randomly crop the image to fit in a (224, 224) area \n",
    "    transforms.RandomRotation((0, 360)),    # randomly rotates the image between 0->360 degrees\n",
    "    transforms.RandomHorizontalFlip(),  # randomly flips the image horisontally\n",
    "    transforms.ColorJitter(brightness=0.5, saturation=0.3, contrast=0.5),   # randomly shifts illumination params\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the augmented dataset\n",
    "With the augmentation pipeline, we just need a strategy to correctly name images, save their labels and write everything to the proper location. First, we load in the labels of the raw dataset as `raw_labels` and create a new pandas dataframe with the same columns for augmented labels: `aug_labels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the labels.csv file into a pandas DF\n",
    "raw_labels = pd.read_csv(list(RAW_LABEL_PATH)[0])\n",
    "# define a new pandas DF for augmented labels\n",
    "aug_labels = pd.DataFrame(columns = raw_labels.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate the full, augmented dataset through the following steps for each image: \n",
    "1. Load the image into memory (`plt.imread`, but PIL/OpenCV ect. all work).\n",
    "2. Extract the image name from the image path `path`, using a split/slice strategy.\n",
    "3. Generate `NUM_AUGMENTATIONS` augmented images by:\n",
    "    1. Create an augmented instance of the image by running it through the defined `augmentation pipeline`\n",
    "    2. Save the augmented image to `data/mushroom_imgs/{filename}` in the target folder. \n",
    "    3. Record the label of the augmented image in `aug_labels`\n",
    "\n",
    "Finally, save the augmented labels `aug_labels` to disk using `pd.dataframe.to_csv(path, index = False, ...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maxime Roedele\\AppData\\Local\\Temp\\ipykernel_1392\\215220478.py:30: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  label = pd.DataFrame([[img_aug_name, int(label)]], columns = raw_labels.columns)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define hyperparameter for the amount of augmentations to make\n",
    "NUM_AUGMENTATIONS = 10\n",
    "\n",
    "# Iterate through all images, making copies of them\n",
    "for path in raw_img_paths:\n",
    "    path = str(path)\n",
    "\n",
    "    # load the image at the path as an ndarray (using plt.imread)\n",
    "    img = plt.imread(path)\n",
    "    # fetch the name of the image by splitting and slicing\n",
    "    img_name = path.split(sep=\"\\\\\")[-1][:-4]\n",
    "\n",
    "    # Augment 'img' NUM_AUGMENTATIONS times, save it to disk and record the new label\n",
    "    for j in range(NUM_AUGMENTATIONS):\n",
    "        # augment the image using the augmentation pipeline\n",
    "        img_aug = augmentation_pipeline(img)\n",
    "\n",
    "        # Define the new image name\n",
    "        img_aug_name = img_name + f\"_{j}\"\n",
    "\n",
    "        # Generate a new path for the image and save it to disk\n",
    "        img_path = f\"{TARGET_DIR}\\{img_aug_name}.jpg\"\n",
    "        img_aug.save(img_path)\n",
    "\n",
    "        # Record the image label in the new csv file\n",
    "        label = raw_labels[raw_labels['image'] == img_name]['label']\n",
    "        label = pd.DataFrame([[img_aug_name, int(label)]], columns = raw_labels.columns)\n",
    "        aug_labels = pd.concat([label, aug_labels])\n",
    "    \n",
    "\n",
    "# Save the augmented image labels to file\n",
    "aug_labels.reset_index(inplace = True)\n",
    "aug_labels.to_csv(TARGET_LABEL_PATH, columns = ['image', 'label'], index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
